{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af08b9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MNIST...\n",
      "Train shape: (4000, 4) Test shape: (1000, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, joblib\n",
    "import pennylane as qml\n",
    "import pennylane.numpy as pnp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- Global config ---\n",
    "SEED = 7\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 32\n",
    "LR = 0.08\n",
    "NOISE_P = 0.02\n",
    "SHOTS = None   # set 4096 for realism\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Choose number of qubits (should match PCA components)\n",
    "N_QUBITS = 4\n",
    "K_BLOCKS = 6   # number of variational layers\n",
    "\n",
    "# --- Load MNIST dataset (replaces Iris/Wine) ---\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def load_dataset(name=\"mnist\"):\n",
    "    if name != \"mnist\":\n",
    "        raise ValueError(\"Only 'mnist' is supported now\")\n",
    "\n",
    "    print(\"Loading MNIST...\")\n",
    "    mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "    X, y = mnist.data / 255.0, mnist.target.astype(int)\n",
    "\n",
    "    # Reduce to N_QUBITS features for quantum input\n",
    "    pca = PCA(n_components=N_QUBITS)\n",
    "    X = pca.fit_transform(X)\n",
    "\n",
    "    # Subsample for quicker training (optional)\n",
    "    X, y = X[:5000], y[:5000]\n",
    "\n",
    "    return X, y, [f\"pca{i}\" for i in range(N_QUBITS)], np.unique(y)\n",
    "\n",
    "# Now load MNIST\n",
    "X, y, feature_names, class_names = load_dataset(\"mnist\")\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    ")\n",
    "\n",
    "print(\"Train shape:\", X_tr.shape, \"Test shape:\", X_te.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c6e668",
   "metadata": {},
   "source": [
    "load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36261596",
   "metadata": {},
   "source": [
    "QNN model (variable qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6657c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.mixed\", wires=N_QUBITS, shots=SHOTS)\n",
    "\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qnn_feature_map(x, theta):\n",
    "    embed_block(x)        # your feature embedding\n",
    "    var_block(theta)      # variational block\n",
    "    return [qml.expval(qml.PauliZ(q)) for q in range(N_QUBITS)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0108ba",
   "metadata": {},
   "source": [
    "Training helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d57567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting QNN features...\n",
      "Feature shape: (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Initialize random parameters for QNN\n",
    "theta_init = rng.normal(size=(N_QUBITS, 3), scale=0.1)\n",
    "\n",
    "def extract_features(X, theta):\n",
    "    feats = []\n",
    "    for x in X:\n",
    "        feats.append(qnn_feature_map(x, theta))\n",
    "    return np.array(feats)\n",
    "\n",
    "print(\"Extracting QNN features...\")\n",
    "X_tr_feats = extract_features(X_tr[:2000], theta_init)   # subsample for speed\n",
    "X_te_feats = extract_features(X_te[:1000], theta_init)\n",
    "\n",
    "print(\"Feature shape:\", X_tr_feats.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26692abf",
   "metadata": {},
   "source": [
    "Train OVR QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b2a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hybrid QNN + Logistic Regression Results:\n",
      "Train acc: 0.3195\n",
      "Test  acc: 0.288\n",
      "\n",
      "Confusion matrix (test):\n",
      " [[37  1 10  1  7  1  4 19 16  0]\n",
      " [ 1 83 11  0  6  0  8  1  2  0]\n",
      " [ 9  4 25  0  0  1 39 12  5  3]\n",
      " [23 26  6  0  6  2 11 11 14  0]\n",
      " [29 10  4  0 11  1  5 28 19  0]\n",
      " [15  6  5  0  8  1 11 12 29  0]\n",
      " [ 2 11 19  2  1  0 50  5 10  0]\n",
      " [21  1 15  2  5  0  6 50  9  1]\n",
      " [17 15  2  0 10  0  1 17 30  0]\n",
      " [23  6  5  0  5  0 10 37 12  1]]\n",
      "\n",
      "Report (test):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.39      0.27        96\n",
      "           1       0.51      0.74      0.60       112\n",
      "           2       0.25      0.26      0.25        98\n",
      "           3       0.00      0.00      0.00        99\n",
      "           4       0.19      0.10      0.13       107\n",
      "           5       0.17      0.01      0.02        87\n",
      "           6       0.34      0.50      0.41       100\n",
      "           7       0.26      0.45      0.33       110\n",
      "           8       0.21      0.33      0.25        92\n",
      "           9       0.20      0.01      0.02        99\n",
      "\n",
      "    accuracy                           0.29      1000\n",
      "   macro avg       0.23      0.28      0.23      1000\n",
      "weighted avg       0.24      0.29      0.24      1000\n",
      "\n",
      "Hybrid QNN model saved as hybrid_qnn_mnist.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shoai\\qml-env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Train a classical softmax classifier on QNN features\n",
    "clf = LogisticRegression(max_iter=500, multi_class=\"multinomial\", solver=\"lbfgs\")\n",
    "clf.fit(X_tr_feats, y_tr[:2000])\n",
    "\n",
    "# Evaluate\n",
    "yhat_tr = clf.predict(X_tr_feats)\n",
    "yhat_te = clf.predict(X_te_feats)\n",
    "\n",
    "print(\"\\nHybrid QNN + Logistic Regression Results:\")\n",
    "print(\"Train acc:\", accuracy_score(y_tr[:2000], yhat_tr))\n",
    "print(\"Test  acc:\", accuracy_score(y_te[:1000], yhat_te))\n",
    "print(\"\\nConfusion matrix (test):\\n\", confusion_matrix(y_te[:1000], yhat_te))\n",
    "print(\"\\nReport (test):\\n\", classification_report(y_te[:1000], yhat_te, target_names=[str(c) for c in class_names]))\n",
    "\n",
    "\n",
    "# Save QNN parameters + classical classifier\n",
    "hybrid_model = {\"theta\": theta_init, \"classifier\": clf}\n",
    "joblib.dump(hybrid_model, \"hybrid_qnn_mnist.joblib\")\n",
    "print(\"Hybrid QNN model saved as hybrid_qnn_mnist.joblib\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37682d4c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a23c8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running robustness experiments...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'theta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nt \u001b[38;5;129;01min\u001b[39;00m noise_types:\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m p_values:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m         y_pred = predict_with_noise(X_te[:\u001b[32m500\u001b[39m], \u001b[43mtheta\u001b[49m, p=p, noise_type=nt)\n\u001b[32m     45\u001b[39m         acc = accuracy_score(y_te[:\u001b[32m500\u001b[39m], y_pred)\n\u001b[32m     46\u001b[39m         results[nt].append(acc)\n",
      "\u001b[31mNameError\u001b[39m: name 'theta' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Noise block with multiple noise types ---\n",
    "def noise_block(p, noise_type=\"depolarizing\"):\n",
    "    if p <= 0:\n",
    "        return\n",
    "    for q in range(N_QUBITS):\n",
    "        if noise_type == \"depolarizing\":\n",
    "            qml.DepolarizingChannel(p, wires=q)\n",
    "        elif noise_type == \"bitflip\":\n",
    "            qml.BitFlip(p, wires=q)\n",
    "        elif noise_type == \"phaseflip\":\n",
    "            qml.PhaseFlip(p, wires=q)\n",
    "        elif noise_type == \"amplitude\":\n",
    "            qml.AmplitudeDamping(p, wires=q)\n",
    "        elif noise_type == \"phase\":\n",
    "            qml.PhaseDamping(p, wires=q)\n",
    "\n",
    "# --- QNN with noise ---\n",
    "@qml.qnode(dev, interface=\"autograd\")\n",
    "def qnn_with_noise(x, theta, p=0.0, noise_type=\"depolarizing\"):\n",
    "    embed_block(x)\n",
    "    var_block(theta)\n",
    "    noise_block(p, noise_type)\n",
    "    return [qml.expval(qml.PauliZ(q)) for q in range(N_QUBITS)]\n",
    "\n",
    "# --- Feature extraction under noise ---\n",
    "def extract_features_with_noise(X, theta, p=0.0, noise_type=\"depolarizing\"):\n",
    "    feats = []\n",
    "    for x in X:\n",
    "        feats.append(qnn_with_noise(x, theta, p=p, noise_type=noise_type))\n",
    "    return np.array(feats)\n",
    "\n",
    "# --- Robustness experiment ---\n",
    "noise_types = [\"depolarizing\", \"bitflip\", \"phaseflip\", \"amplitude\", \"phase\"]\n",
    "p_values = np.linspace(0, 1, 11)  # [0.0, 0.1, ..., 1.0]\n",
    "results = {nt: [] for nt in noise_types}\n",
    "\n",
    "# Load your hybrid model (theta + classifier)\n",
    "hybrid_model = joblib.load(\"hybrid_qnn_mnist.joblib\")\n",
    "theta = hybrid_model[\"theta\"]\n",
    "clf = hybrid_model[\"classifier\"]\n",
    "\n",
    "print(\"\\nRunning robustness experiments on Hybrid QNN...\")\n",
    "\n",
    "for nt in noise_types:\n",
    "    for p in p_values:\n",
    "        X_te_feats_noisy = extract_features_with_noise(X_te[:500], theta, p=p, noise_type=nt)\n",
    "        y_pred = clf.predict(X_te_feats_noisy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
